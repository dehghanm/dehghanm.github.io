<!DOCTYPE html>
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta charset="utf-8">
<meta name="viewport" content="width=device-width initial-scale=1" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Hamed Zamani | resources</title>
<meta name="description" content="Hamed Zamani's Homepage
">
<link rel="shortcut icon" href="http://hamedz.ir/assets/img/favicon.ico">
<link rel="stylesheet" href="assets/css/main.css">
<link rel="canonical" href="resources.html">
</head>
<body>
<header class="site-header">
<div class="wrapper">
<span class="site-title">
<strong>Hamed</strong> Zamani
</span>
<nav class="site-nav">
<div class="trigger">
<a class="page-link" href="index.html">about</a>
<a class="page-link" href="awards.html">awards</a>
<a class="page-link" href="publications.html">publications</a>
<a class="page-link" href="resources.html">resources</a>
<a class="page-link" href="blog.html">blog</a>
</div>
</nav>
</div>
</header>
<div class="page-content">
<div class="wrapper">
<div class="post">
<header class="post-header">
<h1 class="post-title">resources</h1>
<h5 class="post-description"></h5>
</header>
<article class="post-content resources clearfix">
<h3 id="macaw-an-extensible-conversational-information-seeking-platform">Macaw: An Extensible Conversational Information Seeking Platform</h3>
<p>Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval.
Such research will require data and tools, to allow the implementation and study of conversational systems.
Macaw is an open-source framework with a modular architecture for CIS research.
Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, for tasks such as document retrieval, question answering, recommendation, and structured data exploration.
It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode.
It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup.</p>
<p>Macaw could be of interest to the researchers and practitioners working on information retrieval, natural language processing, and dialogue systems.</p>
<p>Macaw is open-sourced under the MIT License, and is accessible through this GitHub repository: <a href="https://github.com/microsoft/macaw" target="\_blank">https://github.com/microsoft/macaw</a></p>
<p>You can cite the following article, if you found Macaw useful:</p>
<ol class="bibliography"><li>
<div id="Zamani:2020:Macaw">
<span class="title">
Macaw: An Extensible Conversational Information Seeking Platform
</span>
<span class="author">
<em>Hamed Zamani</em>,
and
Nick Craswell
</span>
<span class="periodical">
<em>arxiv, </em>
2020
(preprint)
</span>
<span class="links">
[<a href="https://arxiv.org/pdf/1912.08904.pdf" target="_blank">Preprint</a>]
[<a href="https://github.com/microsoft/macaw" target="_blank">Code</a>]
</span>
</div>
</li></ol>
<h3 id="movie-search-ml20-a-known-item-movie-search-dataset-linked-to-movielens-20m">Movie-Search-ML20: A Known-Item Movie Search Dataset Linked to MovieLens 20M</h3>
<p>This dataset is created based on the questions asked by real users in Yahoo! Answers, a community question answering website.
We adopt the data collected by Hagen et al. (2015) from Yahoo! Answers. This dataset focus on the questions in the “movies” category.
This is considered as a known-item search task, where the questions are long and descriptive.
There is a single relevant movie to each question.
We manually mapped each question to its relevant movie ID in the MovieLens 20M dataset.
This allows researchers to have both user-item interactions and query-item relevance signal on the same item set.</p>
<p>The dataset is publicly available for research purposes (<a href="http://ciir.cs.umass.edu/downloads/movie-search-ml20/" target="\_blank">click here</a>). Citation:</p>
<ol class="bibliography"><li>
<div id="Zamani:2020:WSDM">
<span class="title">
Learning a Joint Search and Recommendation Model from User-Item Interactions
</span>
<span class="author">
<em>Hamed Zamani</em>,
and
W. Bruce Croft
</span>
<span class="periodical">
<em>In Proceedings of the 13th ACM International Conference on Web Search and Data Mining, </em>
2020
(WSDM ’20)
</span>
<span class="links">
[<a href="http://maroo.cs.umass.edu/pub/web/getpdf.php?id=1338" target="_blank">Preprint</a>]
</span>
</div>
</li></ol>
<p>Note that this dataset is based on <a href="https://link.springer.com/chapter/10.1007/978-3-319-16354-3_57" target="\_blank">Hagen et al.’s data</a>. If you use this dataset, we encourage you to refer to their work as well.</p>
<h3 id="antique-a-non-factoid-question-answering-dataset">ANTIQUE: A Non-Factoid Question Answering Dataset</h3>
<p>ANTIQUE is an open-domain non-factoid question answering benchmark, collected from diverse categories of Yahoo! Answers.The main characteristics of this dataset include:</p>
<ul>
<li>it solely focuses on non-factoid questions.</li>
<li>it contains relevance judgments for multiple candidate answers per question.</li>
<li>the relevance judgments were collected through crowdsourcing.</li>
<li>it contains over 2.6k questions with over 34k relevance annotations, making ANTIQUE a suitable collection for training complex machine learning QA models, e.g., neural nets.</li>
</ul>
<p>The dataset is publicly available for research purposes (<a href="https://ciir.cs.umass.edu/downloads/Antique/" target="\_blank">click here</a>). Citation:</p>
<ol class="bibliography"><li>
<div id="Hashemi:2020:ECIR">
<span class="title">
ANTIQUE: A Non-Factoid Question Answering Benchmark
</span>
<span class="author">
Helia Hashemi,
Mohammad Aliannejadi,
<em>Hamed Zamani</em>,
and
W. Bruce Croft
</span>
<span class="periodical">
<em>In Proceedings of the 42nd European Conference on Information Retrieval, </em>
2020
(ECIR ’20)
</span>
<span class="links">
[<a href="https://arxiv.org/pdf/1905.08957.pdf" target="_blank">Preprint</a>]
[<a href="https://ciir.cs.umass.edu/downloads/Antique/" target="_blank">Data</a>]
</span>
</div>
</li></ol>
<h3 id="qulac-a-dataset-for-offline-evaluation-of-asking-clarifying-questions">Qulac: A Dataset for Offline Evaluation of Asking Clarifying Questions</h3>
<p>Asking clarifying questions in information retrieval is a technique to identify the user intent behind the submitted query. Clarifying questions are particularly useful in information seeking systems with limited bandwidth interfaces, such as small screens or speech-only interfaces. Qulac was constructed based on the Web search queries used in TREC Web Track 2009-2012 (the ClueWeb09-Category B collection). The clarifying questions and their answers for different facets of the query were collected through crowdsourcing. The constructed data consists of over 10k question-answer pairs on ~200 topics. This dataset enables researchers to evaluate methods for selecting clarifying questions (i.e., offline evaluation). This dataset is a result of a joint effort by researchers from the Università della Svizzera italiana (USI), Lugano, Switzerland and the University of Massachusetts, Amherst, MA, USA. To download the Qulac dataset, please visit <a href="https://github.com/aliannejadi/qulac" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Aliannejadi:2019">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?doid=3331184.3331265" target="_blank">Asking Clarifying Questions in Open-Domain Information Seeking Conversations</a>
</span>
<span class="author">
Mohammad Aliannejadi,
<em>Hamed Zamani</em>,
Fabio Crestani,
and
W. Bruce Croft
</span>
<span class="periodical">
<em>In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, </em>
2019
(SIGIR ’19)
</span>
<span class="links">
[<a href="https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1339" target="_blank">Preprint</a>]
[<a href="https://github.com/aliannejadi/qulac" target="_blank">Data</a>]
</span>
</div>
</li></ol>
<h3 id="telegram-and-twitter-news-data">Telegram (and Twitter) News Data</h3>
<p>Telegram is a popular and fast growing instant messaging service. TelegramNews is a collection of news posts published by a set of popular news agencies through Telegram. This dataset also contains the tweets produced by the same news agencies in the same time period. TelegramNews is publicly available for research purposes. It has been used for news popualrity detection and analysis. It can potentially be used for various tasks, such as news summarization.</p>
<p>This dataset contains telegram posts published by a set of news agencies from their starting date until October 8, 2017. The dataset contains the news posts by BBC, BBC Persian, CNN, Press TV, Reuters World, The Guardian, and Washington Post. The dataset is publicly available <a href="https://bit.ly/TelegramNewsData" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Naseri:2019">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?doid=3331184.3331301" target="_blank">Analyzing and Predicting News Popularity in an Instant Messaging Service</a>
</span>
<span class="author">
Mohammad Naseri,
and
<em>Hamed Zamani</em>
</span>
<span class="periodical">
<em>In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, </em>
2019
(SIGIR ’19)
</span>
<span class="links">
[<a href="https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1312" target="_blank">Preprint</a>]
[<a href="https://bit.ly/TelegramNewsData" target="_blank">Data</a>]
</span>
</div>
</li></ol>
<h3 id="standalone-neural-ranking-model-snrm">Standalone Neural Ranking Model (SNRM)</h3>
<p>SNRM is a framework based on neural networks for end to end document retrieval. SNRM learns a sparse representation for both queries and documents and builds an inverted index based on the learned representations. At the query time, it retrieves documents directly from the whole collection using the learned inverted index. An open-source implementation of SNRM is available <a href="https://github.com/hamed-zamani/snrm" target="\_blank">here</a>.</p>
<ol class="bibliography"><li>
<div id="Zamani:2018:CIKM">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?id=3271800" target="_blank">From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing</a>
</span>
<span class="author">
<em>Hamed Zamani</em>,
Mostafa Dehghani,
W. Bruce Croft,
Erik Learned-Miller,
and
Jaap Kamps
</span>
<span class="periodical">
<em>In Proceedings of the 27th ACM International on Conference on Information and Knowledge Management, </em>
2018
(CIKM ’18)
</span>
<span class="links">
[<a href="https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1302" target="_blank">Preprint</a>]
[<a href="https://github.com/hamed-zamani/snrm" target="_blank">Code</a>]
</span>
</div>
</li></ol>
<h3 id="istas-an-in-situ-dataset-for-target-apps-selection">ISTAS: An In Situ Dataset for Target Apps Selection</h3>
<p>This dataset provides an in situ dataset for target apps selection as part of a unified mobile search system (also see the UniMobile dataset below). In contrast to the UniMobile dataset, ISTAS contains more realistic queries with associated contextual information captured from the mobile sensors and logs of background processes. ISTAS includes over 5000 queries. This dataset is a result of a joint effort by researchers from the Università della Svizzera italiana (USI), Lugano, Switzerland and the University of Massachusetts, Amherst, MA, USA. To download the ISTAS dataset, please visit <a href="http://aliannejadi.com/istas.html" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Aliannejadi:2018:CIKM">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?id=3271679" target="_blank">In Situ and Context-Aware Target Apps Selection for Unified Mobile Search</a>
</span>
<span class="author">
Mohammad Aliannejadi,
<em>Hamed Zamani</em>,
Fabio Crestani,
and
W. Bruce Croft
</span>
<span class="periodical">
<em>In Proceedings of the 27th ACM International on Conference on Information and Knowledge Management, </em>
2018
(CIKM ’18)
</span>
<span class="links">
[<a href="https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1323" target="_blank">Preprint</a>]
[<a href="http://aliannejadi.com/istas.html" target="_blank">Data</a>]
</span>
</div>
</li></ol>
<h3 id="unimobile-a-collection-of-cross-app-mobile-search-queries">UniMobile: A Collection of Cross-App Mobile Search Queries</h3>
<p>As the first step towards developing a unified search framework for mobile devices, the task of Target Apps Selection has been defined. To train and evaluate models for this task, a dataset with over 5000 queries has been built using crowdsourcing. This dataset is a result of a joint effort by researchers from the Università della Svizzera italiana (USI), Lugano, Switzerland and the University of Massachusetts, Amherst, MA, USA. To download the UniMobile dataset, please visit <a href="http://aliannejadi.com/unimobile.html" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Aliannejadi:2018">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?id=3210039" target="_blank">Target Apps Selection: Towards a Unified Search Framework for Mobile Devices</a>
</span>
<span class="author">
Mohammad Aliannejadi,
<em>Hamed Zamani</em>,
Fabio Crestani,
and
W. Bruce Croft
</span>
<span class="periodical">
<em>In Proceedings of the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval, </em>
2018
(SIGIR ’18)
</span>
<span class="links">
[<a href="https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1301" target="_blank">Preprint</a>]
[<a href="http://aliannejadi.com/unimobile.html" target="_blank">Data</a>]
</span>
</div>
</li></ol>
<h3 id="citation-worthiness-dataset">Citation Worthiness Dataset</h3>
<p>Does this sentence need citation? To train and evaluate models for addressing this question, we construct a citation worthiness dataset using the articles of ACL Anthology Reference Corpus (ARC). We use the SEPIC corpus, which includes sentence-level segmentation of 10,921 articles from ACL ARC 1.0, up to February 2007. The sentence splitter and chunker of the Apache OpenNLP 1.5 3 in addition to the Stanford tokenizer and POS tagger, and the MaltParser tools were used. More information is provided in the following paper, and the data can be downloaded from <a href="https://ciir.cs.umass.edu/downloads/sigir18_citation/" target="\_blank">here</a>.</p>
<ol class="bibliography"><li>
<div id="Bonab:2018">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?id=3210162" target="_blank">Citation Worthiness of Sentences in Scientific Reports</a>
</span>
<span class="author">
Hamed Bonab,
<em>Hamed Zamani</em>,
Erik Learned-Miller,
and
James Allan
</span>
<span class="periodical">
<em>In Proceedings of the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval, </em>
2018
(SIGIR ’18)
</span>
<span class="links">
[<a href="https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1314" target="_blank">Preprint</a>]
[<a href="https://ciir.cs.umass.edu/downloads/sigir18_citation/" target="_blank">Data</a>]
</span>
</div>
</li></ol>
<h3 id="million-playlist-dataset">Million Playlist Dataset</h3>
<p>The ACM Recommender Systems Challenge 2018 focuses on a novel task in the field of recommender systems and information retrieval: Automatic Playlist Continuation. RecSys Challenge 2018 is organized by Spotify, University of Massachusetts Amherst, and Johannes Kepler University Linz. For this challenge, Spotify has released a dataset containing one million playlists generated by Spotify users. Please visit <a href="http://www.recsyschallenge.com/2018/" target="\_blank">http://www.recsyschallenge.com/2018/</a> for more information. Citation:</p>
<ol class="bibliography"><li>
<div id="Chen:2018">
<span class="title">
<a href="https://dl.acm.org/citation.cfm?id=3240342" target="_blank">RecSys Challenge 2018: Automatic Music Playlist Continuation</a>
</span>
<span class="author">
Ching-Wei Chen,
Paul Lamere,
Markus Schedl,
and
<em>Hamed Zamani</em>
</span>
<span class="periodical">
<em>In Proceedings of the 12th ACM Conference on Recommender Systems, </em>
2018
(RecSys ’18)
</span>
<span class="links">
</span>
</div>
</li></ol>
<h3 id="tweet-rating-dataset">Tweet Rating Dataset</h3>
<p>This dataset contains tweets of users about the items of four popular and diverse web applications: IMDb (movie), YouTube (video clip), Pandora (music), and Goodreads (book). This dataset contains ~500K tweets from ~20K users about ~230K items (movie, music, etc.). This dataset is freely available for research purposes. Tweet Rating Dataset can be downloaded from <a href="/assets/data/TwitterRatings.zip" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Zamani:2015:AUE:2766462.2767785">
<span class="title">
<a href="http://doi.acm.org/10.1145/2766462.2767785" target="_blank">Adaptive User Engagement Evaluation via Multi-task Learning</a>
</span>
<span class="author">
<em>Hamed Zamani</em>,
Pooya Moradi,
and
Azadeh Shakery
</span>
<span class="periodical">
<em>In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, </em>
2015
(SIGIR ’15)
</span>
<span class="links">
</span>
</div>
</li></ol>
<h3 id="pal-preferenceranking-aggregation-library">PAL: Preference/Ranking Aggregation Library</h3>
<p>This Ruby library contains a few simple rank aggregation methods that we used in ACM RecSysChallenge 2014. The package is open-sourced and can be found <a href="https://github.com/ut-iis/pal" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Zamani:2014:RLR:2668067.2668077">
<span class="title">
<a href="http://doi.acm.org/10.1145/2668067.2668077" target="_blank">Regression and Learning to Rank Aggregation for User Engagement Evaluation</a>
</span>
<span class="author">
<em>Hamed Zamani</em>,
Azadeh Shakery,
and
Pooya Moradi
</span>
<span class="periodical">
<em>In Proceedings of the 2014 Recommender Systems Challenge, </em>
2014
(RecSysChallenge ’14)
</span>
<span class="links">
</span>
</div>
</li></ol>
<h3 id="wikipedia-english-persian-parallel-corpus">Wikipedia English-Persian Parallel Corpus</h3>
<p>This parallel corpus is automatically extracted from English and Persian Wikipedia articles. We extensively evaluate our created parallel corpus to show its high quality compared to the existing English-Persian parallel corpora. This dataset is freely available for research purposes. To download the parallel corpus, please visit <a href="http://eceold.ut.ac.ir/en/project/wikipedia-parallel-corpus" target="\_blank">here</a>. Citation:</p>
<ol class="bibliography"><li>
<div id="Zamani:2016c">
<span class="title">
<a href="https://dx.doi.org/10.1016/j.csl.2016.03.002" target="_blank">Sentence Alignment Using Local and Global Information</a>
</span>
<span class="author">
<em>Hamed Zamani</em>,
Heshaam Faili,
and
Azadeh Shakery
</span>
<span class="periodical">
<em>Computer Speech & Language, </em>
2016
(CSL)
</span>
<span class="links">
</span>
</div>
</li></ol>
</article>
</div>
</div>
</div>
<footer>
<div class="wrapper">
&copy; Copyright 2019 Hamed Zamani.
Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
</div>
</footer>
<script src="jquery-1.12.4.min.js" type="8e8fe045633af0ee60f5b05c-text/javascript"></script>
<script src="assets/js/common.js" type="8e8fe045633af0ee60f5b05c-text/javascript"></script>
<link rel="stylesheet" href="ajax/libs/katex/0-7-1/katex.min.css">
<script src="ajax/libs/katex/0-7-1/katex.min.js" type="8e8fe045633af0ee60f5b05c-text/javascript"></script>
<script src="assets/js/katex.js" type="8e8fe045633af0ee60f5b05c-text/javascript"></script>
<link rel="stylesheet" href="assets/css/font-awesome.min.css">
<link rel="stylesheet" href="assets/css/academicons.min.css">
<script type="8e8fe045633af0ee60f5b05c-text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-XXXXXXXX-X', 'auto');
ga('send', 'pageview');
</script>
<script src="cdn-cgi/scripts/7089c43e/cloudflare-static/rocket-loader.min.js" data-cf-settings="8e8fe045633af0ee60f5b05c-|49" defer=""></script></body>
</html>
